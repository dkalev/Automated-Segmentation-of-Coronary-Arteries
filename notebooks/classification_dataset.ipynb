{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Union, Set, Dict\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_pos_idxs(x:np.ndarray) -> np.ndarray:\n",
    "    return np.stack(np.nonzero(x)).T\n",
    "\n",
    "def get_foreground_idxs(targs:np.ndarray) -> np.ndarray:\n",
    "    return get_pos_idxs(targs)\n",
    "\n",
    "def get_background_idxs(targs:np.ndarray, heart_mask:np.ndarray) -> np.ndarray:\n",
    "    background = (1-targs) * (1-heart_mask)\n",
    "    return get_pos_idxs(1-heart_mask)\n",
    "\n",
    "def filter_invalid_idxs(idxs:np.ndarray, patch_size:int, vol_shape: Tuple[int,int,int]) -> np.ndarray:\n",
    "    idxs = idxs.copy()\n",
    "    fits_left  = np.all((idxs - patch_size / 2) >= 0, axis=1)\n",
    "    fits_right = np.all((idxs + patch_size / 2 - vol_shape) <= 0, axis=1)\n",
    "    return idxs[fits_left&fits_right]\n",
    "\n",
    "def filter_containing_foregroung(targs:np.ndarray, idxs:np.ndarray, patch_size:int, n_samples:int=None, thresh:float=0.0) -> np.ndarray:\n",
    "    n_samples = n_samples or len(idxs)\n",
    "    \n",
    "    res = set()\n",
    "    while len(res) < n_samples:\n",
    "        coords = idxs[np.random.choice(len(idxs), n_samples - len(res), replace=False)]\n",
    "        for coord in coords:\n",
    "            bbox = get_patch_bbox(coord, patch_size)\n",
    "            patch = targs[bbox]\n",
    "            if patch.sum() <= thresh:\n",
    "                res.add(tuple(coord))\n",
    "    return np.array(list(res))\n",
    "\n",
    "def get_patch_bbox(center_coords:np.ndarray, patch_size:int) -> Tuple[slice, slice, slice]:\n",
    "    bbox = np.array([\n",
    "        center_coords - patch_size / 2,\n",
    "        center_coords + patch_size / 2]\n",
    "    )\n",
    "    x, y, z = bbox.T.astype(int)\n",
    "    return slice(x[0],x[1]), slice(y[0],y[1]), slice(z[0],z[1]) \n",
    "\n",
    "def get_vol_id(vol_path):\n",
    "    return int(vol_path.name.split('.')[0])\n",
    "\n",
    "def get_paths(folder:Union[str, Path], sort_fn=lambda x: x) -> List:\n",
    "    paths = [ Path(folder, path) for path in os.listdir(Path(folder))]\n",
    "    paths = sorted(paths, key=sort_fn)\n",
    "    return paths\n",
    "\n",
    "def get_vol_paths(vol_dir:str,\n",
    "                  vol_subdir:str='Train',\n",
    "                  targ_subdir:str='Train_Masks',\n",
    "                  heart_mask_subdir='Train_heart_mask') -> List:\n",
    "    \n",
    "    vol_paths  = get_paths(Path(vol_dir, vol_subdir), sort_fn=get_vol_id)\n",
    "    targ_paths = get_paths(Path(vol_dir, targ_subdir), sort_fn=get_vol_id)\n",
    "    heart_mask_paths = get_paths(Path(vol_dir, heart_mask_subdir), sort_fn=get_vol_id)\n",
    "    \n",
    "    vol_ids = [ get_vol_id(path) for path in vol_paths ]\n",
    "    \n",
    "    return list(zip(vol_ids, vol_paths, targ_paths, heart_mask_paths))\n",
    "\n",
    "def sample_hard_coords(targs: np.ndarray, \n",
    "                       idxs: np.ndarray, \n",
    "                       patch_size:int, \n",
    "                       blacklist: Set[List], \n",
    "                       n_samples:int,\n",
    "                       thresh:float=0.001) -> np.ndarray:\n",
    "    \n",
    "    res = set()\n",
    "    while len(res) < n_samples:\n",
    "        coords = idxs[np.random.choice(len(idxs), n_samples - len(res), replace=False)]\n",
    "        for coord in coords:\n",
    "            if tuple(coord) not in blacklist and tuple(coord) not in res:\n",
    "                bbox = get_patch_bbox(coord, patch_size)\n",
    "                patch = targs[bbox]\n",
    "                if patch.sum() <= thresh:\n",
    "                    res.add(tuple(coord))\n",
    "    return np.array(list(res))\n",
    "\n",
    "def get_pos_coords(targs: np.ndarray, patch_size:int, n_samples:int) -> np.ndarray:\n",
    "    coords = get_foreground_idxs(targs)\n",
    "    coords = filter_invalid_idxs(coords, patch_size, targs.shape)\n",
    "    sampled = np.random.choice(len(coords), n_samples, replace=False)\n",
    "    coords = coords[sampled]\n",
    "    labels = np.ones((len(coords), 1))\n",
    "    return np.hstack([coords, labels])\n",
    "\n",
    "def get_neg_coords(targs:np.ndarray, heart_mask:np.ndarray, patch_size:int, n_samples:int) -> np.ndarray:\n",
    "    coords = get_background_idxs(targs, heart_mask)\n",
    "    coords = filter_invalid_idxs(coords, patch_size, targs.shape)\n",
    "    coords = filter_containing_foregroung(targs, coords, patch_size, n_samples=n_samples)\n",
    "    labels = np.zeros((len(coords), 1))\n",
    "    return np.hstack([coords, labels])\n",
    "\n",
    "def get_vol_hard_mask(vol:np.ndarray, targs:np.ndarray, heart_mask:np.ndarray) -> np.ndarray:\n",
    "    mask = vol * (1-targs) * (1-heart_mask)\n",
    "    mask[(\n",
    "        (mask != 0) & \n",
    "        (mask > np.percentile(mask, 0.05)) &\n",
    "        (mask < np.percentile(mask, 0.95))\n",
    "    )] = 1\n",
    "    return mask\n",
    "\n",
    "def get_hard_neg_coords(vol_hard_mask:np.ndarray,\n",
    "                        targs:np.ndarray,\n",
    "                        already_sampled: Set[Tuple[int,int,int]],\n",
    "                        patch_size:int,\n",
    "                        n_samples:int):\n",
    "    \n",
    "    coords = get_foreground_idxs(vol_hard_mask)\n",
    "    coords = filter_invalid_idxs(coords, patch_size, vol_hard_mask.shape)\n",
    "    coords = sample_hard_coords(targs, coords, patch_size, already_sampled, n_samples=n_samples)\n",
    "    labels = np.zeros((len(coords), 1))\n",
    "    return np.hstack([coords, labels])\n",
    "\n",
    "def normalize_vols(vol_paths:List[Union[Path,str]], output_dir:Union[Path, str], stats:Dict):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for vol_id, path, _, _ in tqdm(vol_paths):\n",
    "        vol, _  = nrrd.read(path, index_order='C')\n",
    "        vol = np.clip(vol, stats['percentile_00_5'], stats['percentile_99_5'])\n",
    "        vol = (vol - stats['mean']) / stats['std']\n",
    "        np.save(Path(output_dir, f'{vol_id}.npy'), vol)\n",
    "\n",
    "def get_patch_coords(vol_paths:List, patch_size:int, n_patches:int=100000):\n",
    "    assert n_patches % 4 == 0\n",
    "    res = {}\n",
    "    n_per_vol = n_patches // len(vol_paths)\n",
    "    \n",
    "    for vol_id, vol_path, targ_path, heart_mask_path in tqdm(vol_paths):\n",
    "        vol           = np.load(vol_path)\n",
    "        targs, _      = nrrd.read(targ_path, index_order='C')\n",
    "        heart_mask, _ = nrrd.read(heart_mask_path, index_order='C')          \n",
    "        \n",
    "        targs = targs.astype(np.uint8)\n",
    "        heart_mask = heart_mask.astype(np.uint8)\n",
    "        \n",
    "        pos_coords = get_pos_coords(targs, patch_size, n_samples=n_per_vol//2)\n",
    "        neg_coords = get_neg_coords(targs, heart_mask, patch_size, n_per_vol//4)\n",
    "        \n",
    "        already_sampled = set([tuple(x) for x in neg_coords[:,:-1].tolist()])\n",
    "        vol_hard_mask = get_vol_hard_mask(vol, targs, heart_mask)\n",
    "        hard_neg_coords = get_hard_neg_coords(vol_hard_mask, targs, already_sampled, patch_size, n_per_vol//4)\n",
    "        \n",
    "        res[vol_id] = np.vstack((pos_coords, neg_coords, hard_neg_coords)).astype(int)\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root = '../dataset/raw/ASOCA2020Data/'\n",
    "processed_subdir = 'processed'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patch_size = 68\n",
    "n_patches = 100000\n",
    "valid_split = [1, 9, 13, 19, 22, 28, 38, 39]\n",
    "stats = {\n",
    "        'mean': 347.14618,\n",
    "        'std': 120.35282,\n",
    "        'percentile_00_5': 95.0,\n",
    "        'percentile_99_5': 698.0,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vol_paths = get_vol_paths(root)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not Path(root, processed_subdir).is_dir() or os.listdir(Path(root, processed_subdir)) == 0:\n",
    "    normalize_vols(vol_paths, Path(root, processed_subdir), stats)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vol_paths = get_vol_paths(root, vol_subdir=processed_subdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patch_idxs = get_patch_coords(vol_paths, patch_size, n_patches=n_patches)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for split in ['train', 'valid']:\n",
    "    os.makedirs(Path(root, processed_subdir, split, 'vols'), exist_ok=True)\n",
    "for vol_id, vol_path, targ_path, _ in vol_paths:\n",
    "    split = 'valid' if vol_id in valid_split else 'train'\n",
    "    os.rename(Path(root, processed_subdir, f'{vol_id}.npy'), Path(root, processed_subdir, split, 'vols', f'{vol_id}.npy'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = {\n",
    "    'stats' : {\n",
    "        'mean': 347.14618,\n",
    "        'std': 120.35282,\n",
    "        'percentile_00_5': 95.0,\n",
    "        'percentile_99_5': 698.0,\n",
    "    },\n",
    "    'patch_size': patch_size,\n",
    "    'patch_stride': 1,\n",
    "    'N': n_patches,\n",
    "    'vol_meta': {\n",
    "        k: {\n",
    "        'split': 'valid' if int(k) in valid_split else 'train',\n",
    "        'n_patches': len(v),\n",
    "        'patches': v.tolist()\n",
    "    }\n",
    "    for k,v in patch_idxs.items()}\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('../dataset/raw/ASOCA2020Data/processed/dataset.json', 'w') as f:\n",
    "    json.dump(dataset, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for vol_id in range(40):\n",
    "    for i, patch in enumerate(dataset['vol_meta'][vol_id]['patches']):\n",
    "        if patch[0] == 0 or patch[1] == 0 or patch[2] == 0:\n",
    "            print(vol_id, i, patch[-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# wrong_label = []\n",
    "pos_sum = 0\n",
    "pos_count = 0\n",
    "neg_sum = 0\n",
    "neg_count = 0\n",
    "for vol_id, coords in patch_idxs.items():\n",
    "    idxs, labels = coords[...,:-1], coords[...,-1]\n",
    "    mask, _ = nrrd.read(Path(root, 'Train_Masks', f'{vol_id}.nrrd'), index_order='C')\n",
    "    for i, idx in enumerate(idxs):\n",
    "        bbox = get_patch_bbox(idx, patch_size)\n",
    "        patch = mask[bbox]\n",
    "        if labels[i] == 1:\n",
    "            pos_count += 1\n",
    "            pos_sum += patch.sum()\n",
    "        elif labels[i] == 0:\n",
    "            neg_count += 1\n",
    "            neg_sum += patch.sum()\n",
    "# assert len(wrong_label) == 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vol = np.load(Path(root, 'processed', '10.npy'))\n",
    "mask, _ = nrrd.read(Path(root, 'Train_Masks', '10.nrrd'), index_order='C')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset['vol_meta'][29]['patches'][-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bbox = get_patch_bbox(np.array([64, 203, 459]), patch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patch = vol[bbox]\n",
    "patch_m = mask[bbox]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import k3d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patch_m.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k3d_volume = k3d.volume(\n",
    "    patch.astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_utils.datamodule import AsocaClassificationDataModule\n",
    "from data_utils.helpers import get_volume_pred\n",
    "from data_utils.helpers_classification import get_patch_bbox\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adm = AsocaClassificationDataModule(data_dir='../dataset/classification', sourcepath='../dataset/ASOCA2020Data.zip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adm.prepare_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dl = adm.train_dataloader()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 10\n",
    "x = torch.empty(n,68,68,68)\n",
    "y = torch.empty(n)\n",
    "meta = []\n",
    "cur = 0\n",
    "for i, batch in enumerate(dl):\n",
    "    if batch[1].item() == 1:\n",
    "        x[cur], y[cur] = batch[:2]\n",
    "        meta.append(batch[2])\n",
    "        cur += 1\n",
    "    if cur == n: break\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "meta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nrrd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask, _ = nrrd.read('../dataset/raw/ASOCA2020Data/Train_Masks/3.nrrd', index_order='C')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('../dataset/classification/dataset.json', 'r') as f:\n",
    "    meta = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_patch = mask[get_patch_bbox(np.array(meta['vol_meta']['3']['patches'][461][:-1]), 68)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import k3d\n",
    "\n",
    "k3d_volume = k3d.volume(\n",
    "    x[7].numpy().astype(np.float32),\n",
    "    alpha_coef=15,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "k3d_volume = k3d.volume(\n",
    "    mask_patch.astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "#     shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Reds,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot += k3d_volume\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dl, meta = adm.volume_dataloader(0, batch_size=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patches = torch.cat(list(iter(dl)))\n",
    "volume_rec = get_volume_pred(patches, meta, [128,128,128], [92,92,92], normalize=False); volume_rec.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "heart_mask, _ = nrrd.read(Path(root, 'Train_heart_mask', '0.nrrd'), index_order='C')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bg = 1 - heart_mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "volume_rec_bg = volume_rec * bg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "volume_hard_mask = volume_rec_bg.copy()\n",
    "volume_hard_mask[(\n",
    "    (volume_hard_mask != 0) & \n",
    "    (volume_hard_mask > np.percentile(volume_hard_mask, 0.05)) &\n",
    "    (volume_hard_mask < np.percentile(volume_hard_mask, 0.95))\n",
    ")] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "volume_rec_bg[volume_rec_bg == 0] = volume_rec_bg.min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k3d_volume = k3d.volume(\n",
    "    volume_hard_mask[::4,::4,::4].astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Baseline3DCNN.load_from_checkpoint('/var/scratch/ebekkers/damyan/models/cnn-baseline-epoch=49-step=7109.ckpt', arch='strided')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "meta['n_patches']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "model.cuda()\n",
    "res = torch.empty((meta['n_patches'], *[92,92,92]))\n",
    "for i, x in enumerate(dl):\n",
    "    preds = model(x.cuda())\n",
    "    preds = torch.sigmoid(preds).round()\n",
    "    res[i] = preds.detach().cpu()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred_rec = get_volume_pred(res, meta, [128,128,128], [92,92,92], normalize=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k3d_volume = k3d.volume(\n",
    "    pred_rec[::4,::4,::4].astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "center_coords = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bboxo = np.array([\n",
    "    center_coords - np.ceil(np.array([5,5,5])/2),\n",
    "    center_coords + np.ceil(np.array([5,5,5])/2),\n",
    "]).T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bboxo.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[ col for row in bboxo for col in row ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.classification.cnn import Baseline3DClassification\n",
    "from data_utils.datamodule import AsocaClassificationDataModule\n",
    "from data_utils.helpers_classification import get_patch_bbox\n",
    "import torch\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adm = AsocaClassificationDataModule(data_dir='../dataset/classification', sourcepath='../dataset/ASOCA2020Data.zip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bs = 16"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dl = adm.val_dataloader(batch_size=bs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Baseline3DClassification.load_from_checkpoint('../wandb/run-20210725_111105-1jyukl95/files/asoca/1jyukl95/checkpoints/epoch=1-step=313.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = torch.nn.DataParallel(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "model.cuda();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "preds = np.empty(1000)\n",
    "targs = np.empty(1000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x, t) in enumerate(dl):\n",
    "        if i >= 100: break\n",
    "        x = x.cuda()\n",
    "        y = torch.sigmoid(model(x)).round()\n",
    "        targs[i*bs:i*bs+len(t)] = t.cpu().squeeze(-1).numpy()\n",
    "        preds[i*bs:i*bs+len(y)] = y.cpu().squeeze(-1).numpy()"
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "preds = preds[:-8]\n",
    "\n",
    "targs = targs[:-8]\n",
    "\n",
    "(targs == preds).mean()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nrrd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from data_utils.helpers_classification import get_foreground_idxs, filter_invalid_idxs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vol, _ = nrrd.read('../dataset/raw/ASOCA2020Data/Train/1.nrrd', index_order='C')\n",
    "mask, _ = nrrd.read('../dataset/raw/ASOCA2020Data/Train_Masks/1.nrrd', index_order='C')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims = vol.shape\n",
    "dims_max = dims - np.array([57,150,150])\n",
    "dims_min = np.array([57,150,150])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred_shape = dims_max-dims_min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "targ_center = np.array([112, 239, 142])"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "targs = mask[get_patch_bbox(targ_center, 68)]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "targs = mask[\n",
    "    dims_min[0]:dims_max[0],\n",
    "    dims_min[1]:dims_max[1],\n",
    "    dims_min[2]:dims_max[2],\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = np.load('../class_vol_preds_136_6201.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.imshow(preds.sum(axis=1)[:-14].reshape(-1, 28))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "preds = np.concatenate((preds.flatten(), np.zeros(32))).reshape((68,68,68))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voxels = np.stack(np.meshgrid(\n",
    "    np.arange(dims_min[0], dims_max[0]),\n",
    "    np.arange(dims_min[1], dims_max[1]),\n",
    "    np.arange(dims_min[2], dims_max[2]),\n",
    "    indexing='ij'\n",
    ")).T.reshape((-1,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.stack(np.meshgrid(\n",
    "    np.arange(dims_min[0], dims_max[0]),\n",
    "    np.arange(dims_min[1], dims_max[1]),\n",
    "    np.arange(dims_min[2], dims_max[2]),\n",
    "    indexing='ij'\n",
    ")).shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred_shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = np.concatenate((preds.flatten(), np.zeros(136))).reshape((212,69,212))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(preds * targs).mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import k3d\n",
    "k3d_volume = k3d.volume(\n",
    "    preds.transpose(1,0,2).astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "k3d_volume = k3d.volume(\n",
    "    targs.astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Greens,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "\n",
    "# plot += k3d_volume\n",
    "\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "8**3 / 68**3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('../dataset/classification/dataset.json', 'r') as f:\n",
    "    meta = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stats = meta['stats']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vol = np.clip(vol, stats['percentile_00_5'], stats['percentile_99_5'])\n",
    "vol = (vol - stats['mean']) / stats['std']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims = np.array(vol.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims_max = dims - np.array([57,150,150])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims_min = np.array([57,150,150])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims_min, dims_max"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "meta['vol_meta']['1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "center = np.array([112, 239, 142])\n",
    "left = center - 34\n",
    "right = center + 34"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voxels = np.stack(np.meshgrid(\n",
    "    np.arange(left[0], right[0]),\n",
    "    np.arange(left[1], right[1]),\n",
    "    np.arange(left[2], right[2])\n",
    ")).T.reshape((-1,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voxels = np.stack(np.meshgrid(\n",
    "    np.arange(dims_min[0], dims_max[0]),\n",
    "    np.arange(dims_min[1], dims_max[1]),\n",
    "    np.arange(dims_min[2], dims_max[2])\n",
    ")).T.reshape((-1,3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bs = 600"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remainder = len(voxels) - bs * (len(voxels)//bs)\n",
    "\n",
    "voxels = voxels[:-remainder]\n",
    "\n",
    "voxels = voxels.reshape(-1,bs,3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voxels.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = np.empty_like(voxels.shape[:2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, voxels.shape[0]*voxels.shape[1] // bs)):\n",
    "        x = np.empty((bs,68,68,68))\n",
    "        for j in range(bs):\n",
    "            x[j] = vol[get_patch_bbox(voxels[i][j], 68)]\n",
    "        x = torch.from_numpy(x).float().unsqueeze(1).cuda()\n",
    "        y = torch.sigmoid(model(x)).round()\n",
    "        preds[i] = y.cpu().squeeze(-1).numpy()\n",
    "        if i % 500 == 0: np.save(f'class_vol_preds_{i}.npy', preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds_vol = np.concatenate((preds, np.zeros(remainder))).reshape(dims_max-dims_min)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import k3d\n",
    "k3d_volume = k3d.volume(\n",
    "    preds_vol.astype(np.float32),\n",
    "    alpha_coef=1000,\n",
    "    shadow='dynamic',\n",
    "    samples=600,\n",
    "    color_map=k3d.colormaps.paraview_color_maps.Coolwarm,\n",
    "    compression_level=9\n",
    ")\n",
    "\n",
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "plot += k3d_volume\n",
    "\n",
    "plot.lighting = 2\n",
    "plot.display()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remainder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.save(f'../class_vol_preds_{i}.npy', preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = np.load('../class_vol_preds_5167.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dims_max - dims_min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "3100800 / (94*330*330)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds.reshape((94,330,-1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds.sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.save('preds.npy', preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "patch = vol[get_patch_bbox(voxels[-1][120], 68)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = model(torch.from_numpy(patch).float().unsqueeze(0).unsqueeze(0).cuda())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.sigmoid(pred).item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "voxels.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}